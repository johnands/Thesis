\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}
\contentsline {section}{\numberline {1.1}Goals}{1}{section.1.1}
\contentsline {part}{I\hspace {1em}Theory}{3}{part.1}
\contentsline {chapter}{\numberline {2}Molecular dynamics}{7}{chapter.2}
\contentsline {section}{\numberline {2.1}Potential energy surfaces}{7}{section.2.1}
\contentsline {subsection}{\numberline {2.1.1}From quantum mechanics to classical potentials}{8}{subsection.2.1.1}
\contentsline {subsection}{\numberline {2.1.2}Constructing potential energy surfaces}{8}{subsection.2.1.2}
\contentsline {subsubsection}{Truncation and configuration space}{9}{section*.2}
\contentsline {subsubsection}{Fitting procedure}{9}{section*.3}
\contentsline {section}{\numberline {2.2}Common empirical potentials}{10}{section.2.2}
\contentsline {subsection}{\numberline {2.2.1}Lennard-Jones}{10}{subsection.2.2.1}
\contentsline {subsubsection}{Calculating total potential energy}{12}{section*.5}
\contentsline {subsection}{\numberline {2.2.2}Stillinger-Weber}{13}{subsection.2.2.2}
\contentsline {subsection}{\numberline {2.2.3}Vashishta}{13}{subsection.2.2.3}
\contentsline {section}{\numberline {2.3}Time integration}{14}{section.2.3}
\contentsline {section}{\numberline {2.4}Force calculations and cutoff radius}{15}{section.2.4}
\contentsline {chapter}{\numberline {3}Machine learning}{17}{chapter.3}
\contentsline {section}{\numberline {3.1}Artificial neurons}{18}{section.3.1}
\contentsline {section}{\numberline {3.2}Neural network types}{20}{section.3.2}
\contentsline {subsection}{\numberline {3.2.1}Feed-forward neural networks}{21}{subsection.3.2.1}
\contentsline {subsection}{\numberline {3.2.2}Recurrent neural networks}{22}{subsection.3.2.2}
\contentsline {subsection}{\numberline {3.2.3}Other types of networks}{22}{subsection.3.2.3}
\contentsline {section}{\numberline {3.3}Multilayer perceptron}{23}{section.3.3}
\contentsline {subsection}{\numberline {3.3.1}Why multilayer perceptrons?}{23}{subsection.3.3.1}
\contentsline {subsection}{\numberline {3.3.2}Mathematical model}{24}{subsection.3.3.2}
\contentsline {subsubsection}{Activation function of output neuron}{26}{section*.14}
\contentsline {subsubsection}{Matrix representation}{26}{section*.15}
\contentsline {section}{\numberline {3.4}Activation functions}{28}{section.3.4}
\contentsline {section}{\numberline {3.5}Training}{30}{section.3.5}
\contentsline {subsection}{\numberline {3.5.1}Cost functions}{31}{subsection.3.5.1}
\contentsline {section}{\numberline {3.6}Optimization}{32}{section.3.6}
\contentsline {subsection}{\numberline {3.6.1}Gradient descent variants}{32}{subsection.3.6.1}
\contentsline {subsection}{\numberline {3.6.2}Optimization algorithms}{33}{subsection.3.6.2}
\contentsline {subsubsection}{Momentum}{33}{section*.18}
\contentsline {subsubsection}{Adagrad}{33}{section*.19}
\contentsline {subsubsection}{Adadelta}{34}{section*.20}
\contentsline {subsubsection}{Adam}{35}{section*.21}
\contentsline {subsubsection}{Which optimizer to use?}{35}{section*.22}
\contentsline {subsection}{\numberline {3.6.3}Backpropagation}{36}{subsection.3.6.3}
\contentsline {subsubsection}{1. Forward propagation}{36}{section*.23}
\contentsline {subsubsection}{2. Backward propagation}{37}{section*.24}
\contentsline {subsubsection}{Matrix notation}{39}{section*.26}
\contentsline {subsubsection}{Training algorithm}{40}{section*.27}
\contentsline {chapter}{\numberline {4}Neural networks in molecular dynamics}{43}{chapter.4}
\contentsline {section}{\numberline {4.1}Neural network potentials}{43}{section.4.1}
\contentsline {subsection}{\numberline {4.1.1}Potentials using single neural network}{43}{subsection.4.1.1}
\contentsline {subsection}{\numberline {4.1.2}Potentials using multiple neural networks}{44}{subsection.4.1.2}
\contentsline {section}{\numberline {4.2}The Behler-Parinello method}{44}{section.4.2}
\contentsline {subsection}{\numberline {4.2.1}Symmetry functions}{45}{subsection.4.2.1}
\contentsline {subsubsection}{Radial symmetry functions}{46}{section*.29}
\contentsline {subsubsection}{Angular symmetry functions}{49}{section*.31}
\contentsline {subsection}{\numberline {4.2.2}Symmetry functions and forces}{50}{subsection.4.2.2}
\contentsline {subsubsection}{Change of coordinates}{51}{section*.33}
\contentsline {subsection}{\numberline {4.2.3}Summary}{54}{subsection.4.2.3}
\contentsline {part}{II\hspace {1em}Implementation and results}{55}{part.2}
\contentsline {chapter}{\numberline {5}LAMMPS}{57}{chapter.5}
\contentsline {section}{\numberline {5.1}Installing LAMMPS}{57}{section.5.1}
\contentsline {section}{\numberline {5.2}LAMMPS input script}{58}{section.5.2}
\contentsline {section}{\numberline {5.3}LAMMPS structure}{62}{section.5.3}
\contentsline {section}{\numberline {5.4}Extending LAMMPS}{62}{section.5.4}
\contentsline {chapter}{\numberline {6}TensorFlow}{71}{chapter.6}
\contentsline {section}{\numberline {6.1}Installing TensorFlow}{72}{section.6.1}
\contentsline {section}{\numberline {6.2}TensorFlow basic usage}{73}{section.6.2}
\contentsline {subsection}{\numberline {6.2.1}Hello world}{73}{subsection.6.2.1}
\contentsline {subsection}{\numberline {6.2.2}Creating a neural network}{74}{subsection.6.2.2}
\contentsline {subsection}{\numberline {6.2.3}Visualizing the graph}{75}{subsection.6.2.3}
\contentsline {subsection}{\numberline {6.2.4}Training a NN with TensorFlow}{77}{subsection.6.2.4}
\contentsline {chapter}{\numberline {7}Constructing a neural network potential}{81}{chapter.7}
\contentsline {section}{\numberline {7.1}Selecting the training data}{81}{section.7.1}
\contentsline {subsection}{\numberline {7.1.1}Iterative molecular dynamics sampling}{82}{subsection.7.1.1}
\contentsline {subsection}{\numberline {7.1.2}Sampling algorithms}{83}{subsection.7.1.2}
\contentsline {subsubsection}{Initial sampling}{84}{section*.39}
\contentsline {subsubsection}{Iterative sampling}{88}{section*.41}
\contentsline {subsubsection}{Summary}{89}{section*.42}
\contentsline {section}{\numberline {7.2}Constructing the symmetry function sets}{90}{section.7.2}
\contentsline {subsection}{\numberline {7.2.1}Initial set}{90}{subsection.7.2.1}
\contentsline {subsection}{\numberline {7.2.2}Adjusting the set}{91}{subsection.7.2.2}
\contentsline {subsubsection}{The range of each symmetry function}{92}{section*.45}
\contentsline {subsubsection}{Correlations}{92}{section*.46}
\contentsline {chapter}{\numberline {8}Details on training}{95}{chapter.8}
\contentsline {section}{\numberline {8.1}Training parameters}{95}{section.8.1}
\contentsline {section}{\numberline {8.2}Transfer NN from Python to C++}{95}{section.8.2}
\contentsline {chapter}{\numberline {9}Validation}{99}{chapter.9}
\contentsline {section}{\numberline {9.1}Training Lennard-Jones potential}{99}{section.9.1}
\contentsline {subsection}{\numberline {9.1.1}Many-neighbour Lennard-Jones}{101}{subsection.9.1.1}
\contentsline {chapter}{\numberline {10}NN potential for Si}{107}{chapter.10}
\contentsline {chapter}{\numberline {11}NN potential for SiO2}{109}{chapter.11}
\contentsline {part}{III\hspace {1em}Conclusions and future work}{111}{part.3}
\contentsline {chapter}{\numberline {12}The quality of the NNP}{113}{chapter.12}
\contentsline {chapter}{Appendices}{115}{section*.53}
\contentsline {chapter}{\numberline {A}Symmetry functions derivatives}{117}{Appendix.1.A}
