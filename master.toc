\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}
\contentsline {section}{\numberline {1.1}Goals}{1}{section.1.1}
\contentsline {part}{I\hspace {1em}Theory}{3}{part.1}
\contentsline {chapter}{\numberline {2}Molecular dynamics}{7}{chapter.2}
\contentsline {section}{\numberline {2.1}Potential energy surfaces}{7}{section.2.1}
\contentsline {subsection}{\numberline {2.1.1}From quantum mechanics to classical potentials}{8}{subsection.2.1.1}
\contentsline {subsection}{\numberline {2.1.2}Constructing potential energy surfaces}{9}{subsection.2.1.2}
\contentsline {section}{\numberline {2.2}Time integration}{9}{section.2.2}
\contentsline {section}{\numberline {2.3}Empirical potentials}{10}{section.2.3}
\contentsline {subsection}{\numberline {2.3.1}Lennard-Jones}{10}{subsection.2.3.1}
\contentsline {subsection}{\numberline {2.3.2}Stillinger-Weber}{10}{subsection.2.3.2}
\contentsline {subsection}{\numberline {2.3.3}Vashishta}{10}{subsection.2.3.3}
\contentsline {section}{\numberline {2.4}Advanced theory}{10}{section.2.4}
\contentsline {subsection}{\numberline {2.4.1}Verlet lists}{10}{subsection.2.4.1}
\contentsline {subsection}{\numberline {2.4.2}Thermostats / ensembles}{10}{subsection.2.4.2}
\contentsline {chapter}{\numberline {3}Machine learning}{11}{chapter.3}
\contentsline {section}{\numberline {3.1}Artificial neurons}{12}{section.3.1}
\contentsline {section}{\numberline {3.2}Neural network types}{14}{section.3.2}
\contentsline {subsection}{\numberline {3.2.1}Feed-forward neural networks}{15}{subsection.3.2.1}
\contentsline {subsection}{\numberline {3.2.2}Recurrent neural networks}{16}{subsection.3.2.2}
\contentsline {subsection}{\numberline {3.2.3}Other types of networks}{16}{subsection.3.2.3}
\contentsline {section}{\numberline {3.3}Multilayer perceptron}{17}{section.3.3}
\contentsline {subsection}{\numberline {3.3.1}Why multilayer perceptrons?}{17}{subsection.3.3.1}
\contentsline {subsection}{\numberline {3.3.2}Mathematical model}{18}{subsection.3.3.2}
\contentsline {subsubsection}{Activation function of output neuron}{20}{section*.9}
\contentsline {subsubsection}{Matrix representation}{20}{section*.10}
\contentsline {section}{\numberline {3.4}Activation functions}{22}{section.3.4}
\contentsline {section}{\numberline {3.5}Training}{24}{section.3.5}
\contentsline {subsection}{\numberline {3.5.1}Cost functions}{25}{subsection.3.5.1}
\contentsline {section}{\numberline {3.6}Optimization}{26}{section.3.6}
\contentsline {subsection}{\numberline {3.6.1}Gradient descent variants}{26}{subsection.3.6.1}
\contentsline {subsection}{\numberline {3.6.2}Optimization algorithms}{27}{subsection.3.6.2}
\contentsline {subsubsection}{Momentum}{27}{section*.13}
\contentsline {subsubsection}{Adagrad}{27}{section*.14}
\contentsline {subsubsection}{Adadelta}{28}{section*.15}
\contentsline {subsubsection}{Adam}{29}{section*.16}
\contentsline {subsubsection}{Which optimizer to use?}{29}{section*.17}
\contentsline {subsection}{\numberline {3.6.3}Backpropagation}{30}{subsection.3.6.3}
\contentsline {subsubsection}{1. Forward propagation}{30}{section*.18}
\contentsline {subsubsection}{2. Backward propagation}{31}{section*.19}
\contentsline {subsubsection}{Matrix notation}{33}{section*.21}
\contentsline {subsubsection}{Training algorithm}{34}{section*.22}
\contentsline {chapter}{\numberline {4}Neural networks in molecular dynamics}{37}{chapter.4}
\contentsline {section}{\numberline {4.1}High-dimensional NNPs}{38}{section.4.1}
\contentsline {subsection}{\numberline {4.1.1}Symmetry functions}{40}{subsection.4.1.1}
\contentsline {subsection}{\numberline {4.1.2}Symmetry functions and forces}{45}{subsection.4.1.2}
\contentsline {part}{II\hspace {1em}Implementation and validation}{49}{part.2}
\contentsline {chapter}{\numberline {5}LAMMPS}{51}{chapter.5}
\contentsline {subsection}{\numberline {5.0.1}Installing LAMMPS}{51}{subsection.5.0.1}
\contentsline {subsection}{\numberline {5.0.2}LAMMPS input script}{52}{subsection.5.0.2}
\contentsline {subsection}{\numberline {5.0.3}LAMMPS structure}{56}{subsection.5.0.3}
\contentsline {subsection}{\numberline {5.0.4}Extending LAMMPS}{56}{subsection.5.0.4}
\contentsline {chapter}{\numberline {6}TensorFlow}{59}{chapter.6}
\contentsline {section}{\numberline {6.1}Installing TensorFlow}{60}{section.6.1}
\contentsline {section}{\numberline {6.2}TensorFlow basic usage}{60}{section.6.2}
\contentsline {subsection}{\numberline {6.2.1}Hello world}{61}{subsection.6.2.1}
\contentsline {subsection}{\numberline {6.2.2}Creating a neural network}{61}{subsection.6.2.2}
\contentsline {subsection}{\numberline {6.2.3}Visualizing the graph}{63}{subsection.6.2.3}
\contentsline {subsection}{\numberline {6.2.4}Training a NN with TensorFlow}{66}{subsection.6.2.4}
\contentsline {chapter}{\numberline {7}Training procedure}{71}{chapter.7}
\contentsline {section}{\numberline {7.1}Selecting the training data}{71}{section.7.1}
\contentsline {subsection}{\numberline {7.1.1}Iterative molecular dynamics sampling}{72}{subsection.7.1.1}
\contentsline {subsection}{\numberline {7.1.2}Sampling algorithms}{73}{subsection.7.1.2}
\contentsline {subsubsection}{Initial sampling}{74}{section*.29}
\contentsline {subsubsection}{Iterative sampling}{78}{section*.31}
\contentsline {subsubsection}{Summary}{79}{section*.32}
\contentsline {section}{\numberline {7.2}Constructing the symmetry function sets}{80}{section.7.2}
\contentsline {chapter}{\numberline {8}Validation}{83}{chapter.8}
\contentsline {section}{\numberline {8.1}Time usage}{83}{section.8.1}
\contentsline {section}{\numberline {8.2}Training Lennard-Jones potential}{85}{section.8.2}
\contentsline {subsection}{\numberline {8.2.1}Many-neighbour Lennard-Jones}{87}{subsection.8.2.1}
\contentsline {part}{III\hspace {1em}Results and discussion}{93}{part.3}
\contentsline {chapter}{\numberline {9}NN potential for Si}{95}{chapter.9}
\contentsline {chapter}{\numberline {10}NN potential for SiO2}{97}{chapter.10}
\contentsline {chapter}{Appendices}{99}{section*.39}
\contentsline {chapter}{\numberline {A}Symmetry functions derivatives}{101}{Appendix.1.A}
