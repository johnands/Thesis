\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}
\contentsline {section}{\numberline {1.1}Goals}{1}{section.1.1}
\contentsline {part}{I\hspace {1em}Theory}{3}{part.1}
\contentsline {chapter}{\numberline {2}Molecular dynamics}{7}{chapter.2}
\contentsline {section}{\numberline {2.1}Potential energy surfaces}{7}{section.2.1}
\contentsline {subsection}{\numberline {2.1.1}From quantum mechanics to classical potentials}{8}{subsection.2.1.1}
\contentsline {subsection}{\numberline {2.1.2}Constructing potential energy surfaces}{8}{subsection.2.1.2}
\contentsline {subsubsection}{Truncation and configuration space}{9}{section*.2}
\contentsline {subsubsection}{Fitting procedure}{9}{section*.3}
\contentsline {section}{\numberline {2.2}Common empirical potentials}{10}{section.2.2}
\contentsline {subsection}{\numberline {2.2.1}Lennard-Jones}{10}{subsection.2.2.1}
\contentsline {subsubsection}{Calculating total potential energy}{12}{section*.5}
\contentsline {subsection}{\numberline {2.2.2}Stillinger-Weber}{13}{subsection.2.2.2}
\contentsline {subsection}{\numberline {2.2.3}Vashishta}{13}{subsection.2.2.3}
\contentsline {section}{\numberline {2.3}Time integration}{14}{section.2.3}
\contentsline {section}{\numberline {2.4}Force calculations and cutoff radius}{15}{section.2.4}
\contentsline {chapter}{\numberline {3}Machine learning}{17}{chapter.3}
\contentsline {section}{\numberline {3.1}Artificial neurons}{18}{section.3.1}
\contentsline {section}{\numberline {3.2}Neural network types}{20}{section.3.2}
\contentsline {subsection}{\numberline {3.2.1}Feed-forward neural networks}{21}{subsection.3.2.1}
\contentsline {subsection}{\numberline {3.2.2}Recurrent neural networks}{22}{subsection.3.2.2}
\contentsline {subsection}{\numberline {3.2.3}Other types of networks}{22}{subsection.3.2.3}
\contentsline {section}{\numberline {3.3}Multilayer perceptron}{23}{section.3.3}
\contentsline {subsection}{\numberline {3.3.1}Why multilayer perceptrons?}{23}{subsection.3.3.1}
\contentsline {subsection}{\numberline {3.3.2}Mathematical model}{24}{subsection.3.3.2}
\contentsline {subsubsection}{Activation function of output neuron}{26}{section*.14}
\contentsline {subsubsection}{Matrix representation}{26}{section*.15}
\contentsline {section}{\numberline {3.4}Activation functions}{28}{section.3.4}
\contentsline {section}{\numberline {3.5}Training}{30}{section.3.5}
\contentsline {subsection}{\numberline {3.5.1}Cost functions}{31}{subsection.3.5.1}
\contentsline {section}{\numberline {3.6}Optimization}{32}{section.3.6}
\contentsline {subsection}{\numberline {3.6.1}Gradient descent variants}{32}{subsection.3.6.1}
\contentsline {subsection}{\numberline {3.6.2}Optimization algorithms}{33}{subsection.3.6.2}
\contentsline {subsubsection}{Momentum}{33}{section*.18}
\contentsline {subsubsection}{Adagrad}{33}{section*.19}
\contentsline {subsubsection}{Adadelta}{34}{section*.20}
\contentsline {subsubsection}{Adam}{35}{section*.21}
\contentsline {subsubsection}{Which optimizer to use?}{35}{section*.22}
\contentsline {subsection}{\numberline {3.6.3}Backpropagation}{36}{subsection.3.6.3}
\contentsline {subsubsection}{1. Forward propagation}{36}{section*.23}
\contentsline {subsubsection}{2. Backward propagation}{37}{section*.24}
\contentsline {subsubsection}{Matrix notation}{39}{section*.26}
\contentsline {subsubsection}{Training algorithm}{40}{section*.27}
\contentsline {chapter}{\numberline {4}Neural networks in molecular dynamics}{43}{chapter.4}
\contentsline {section}{\numberline {4.1}Neural network potentials}{43}{section.4.1}
\contentsline {subsection}{\numberline {4.1.1}Potentials using single neural network}{43}{subsection.4.1.1}
\contentsline {subsection}{\numberline {4.1.2}Potentials using multiple neural networks}{44}{subsection.4.1.2}
\contentsline {section}{\numberline {4.2}The Behler-Parinello method}{44}{section.4.2}
\contentsline {subsection}{\numberline {4.2.1}Symmetry functions}{45}{subsection.4.2.1}
\contentsline {subsubsection}{Radial symmetry functions}{46}{section*.29}
\contentsline {subsubsection}{Angular symmetry functions}{49}{section*.31}
\contentsline {subsubsection}{Setting the symmetry parameters}{49}{section*.33}
\contentsline {subsection}{\numberline {4.2.2}Symmetry functions and forces}{50}{subsection.4.2.2}
\contentsline {subsubsection}{Change of coordinates}{52}{section*.34}
\contentsline {subsection}{\numberline {4.2.3}Summary}{54}{subsection.4.2.3}
\contentsline {part}{II\hspace {1em}Implementation and results}{57}{part.2}
\contentsline {chapter}{\numberline {5}LAMMPS}{59}{chapter.5}
\contentsline {section}{\numberline {5.1}Installing LAMMPS}{59}{section.5.1}
\contentsline {section}{\numberline {5.2}LAMMPS input script}{60}{section.5.2}
\contentsline {section}{\numberline {5.3}LAMMPS structure}{64}{section.5.3}
\contentsline {section}{\numberline {5.4}Extending LAMMPS}{64}{section.5.4}
\contentsline {chapter}{\numberline {6}TensorFlow}{73}{chapter.6}
\contentsline {section}{\numberline {6.1}Installing TensorFlow}{74}{section.6.1}
\contentsline {section}{\numberline {6.2}TensorFlow basic usage}{75}{section.6.2}
\contentsline {subsection}{\numberline {6.2.1}Hello world}{75}{subsection.6.2.1}
\contentsline {subsection}{\numberline {6.2.2}Creating a neural network}{76}{subsection.6.2.2}
\contentsline {subsection}{\numberline {6.2.3}Visualizing the graph}{77}{subsection.6.2.3}
\contentsline {subsection}{\numberline {6.2.4}Training a NN with TensorFlow}{79}{subsection.6.2.4}
\contentsline {chapter}{\numberline {7}Constructing a neural network potential}{83}{chapter.7}
\contentsline {section}{\numberline {7.1}Selecting the training data}{83}{section.7.1}
\contentsline {subsection}{\numberline {7.1.1}Iterative molecular dynamics sampling}{84}{subsection.7.1.1}
\contentsline {subsection}{\numberline {7.1.2}Sampling algorithms}{85}{subsection.7.1.2}
\contentsline {subsubsection}{Initial sampling}{86}{section*.40}
\contentsline {subsubsection}{Iterative sampling}{90}{section*.42}
\contentsline {subsubsection}{Summary}{91}{section*.43}
\contentsline {section}{\numberline {7.2}Constructing the symmetry function sets}{92}{section.7.2}
\contentsline {subsection}{\numberline {7.2.1}Initial set}{92}{subsection.7.2.1}
\contentsline {subsection}{\numberline {7.2.2}Adjusting the set}{93}{subsection.7.2.2}
\contentsline {subsubsection}{The range of each symmetry function}{94}{section*.46}
\contentsline {subsubsection}{Correlations}{94}{section*.47}
\contentsline {section}{\numberline {7.3}Details on training}{95}{section.7.3}
\contentsline {subsection}{\numberline {7.3.1}Preconditioning the input data}{95}{subsection.7.3.1}
\contentsline {section}{\numberline {7.4}Determine hyperparameters}{96}{section.7.4}
\contentsline {section}{\numberline {7.5}Transfer NN from Python to C++}{97}{section.7.5}
\contentsline {chapter}{\numberline {8}Validation}{101}{chapter.8}
\contentsline {section}{\numberline {8.1}Training Lennard-Jones potential}{101}{section.8.1}
\contentsline {subsection}{\numberline {8.1.1}Many-neighbour Lennard-Jones}{103}{subsection.8.1.1}
\contentsline {chapter}{\numberline {9}NN potential for Si}{109}{chapter.9}
\contentsline {chapter}{\numberline {10}NN potential for SiO2}{111}{chapter.10}
\contentsline {part}{III\hspace {1em}Conclusions and future work}{113}{part.3}
\contentsline {chapter}{\numberline {11}The quality of the NNP}{115}{chapter.11}
\contentsline {chapter}{Appendices}{117}{section*.54}
\contentsline {chapter}{\numberline {A}Symmetry functions derivatives}{119}{Appendix.1.A}
