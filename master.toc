\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}
\contentsline {section}{\numberline {1.1}Potentials in molecular dynamics}{1}{section.1.1}
\contentsline {section}{\numberline {1.2}Neural Network potentials}{2}{section.1.2}
\contentsline {section}{\numberline {1.3}Goals}{3}{section.1.3}
\contentsline {section}{\numberline {1.4}Our contributions}{4}{section.1.4}
\contentsline {section}{\numberline {1.5}Structure of the thesis}{5}{section.1.5}
\contentsline {part}{I\hspace {1em}Theory}{7}{part.1}
\contentsline {chapter}{\numberline {2}Molecular dynamics}{9}{chapter.2}
\contentsline {section}{\numberline {2.1}Potential energy surfaces}{9}{section.2.1}
\contentsline {subsection}{\numberline {2.1.1}From quantum mechanics to classical potentials}{10}{subsection.2.1.1}
\contentsline {subsection}{\numberline {2.1.2}Constructing potential energy surfaces}{10}{subsection.2.1.2}
\contentsline {subsubsection}{Truncation and configuration space}{11}{section*.2}
\contentsline {subsubsection}{Fitting procedure}{11}{section*.3}
\contentsline {section}{\numberline {2.2}Common empirical potentials}{12}{section.2.2}
\contentsline {subsection}{\numberline {2.2.1}Lennard-Jones}{12}{subsection.2.2.1}
\contentsline {subsubsection}{Calculating total potential energy}{14}{section*.5}
\contentsline {subsection}{\numberline {2.2.2}Stillinger-Weber}{15}{subsection.2.2.2}
\contentsline {subsection}{\numberline {2.2.3}Vashishta}{15}{subsection.2.2.3}
\contentsline {section}{\numberline {2.3}Time integration}{16}{section.2.3}
\contentsline {section}{\numberline {2.4}Force calculations and cutoff radius}{17}{section.2.4}
\contentsline {chapter}{\numberline {3}Machine learning}{19}{chapter.3}
\contentsline {section}{\numberline {3.1}Artificial neurons}{20}{section.3.1}
\contentsline {section}{\numberline {3.2}Neural network types}{22}{section.3.2}
\contentsline {subsection}{\numberline {3.2.1}Feed-forward neural networks}{23}{subsection.3.2.1}
\contentsline {subsection}{\numberline {3.2.2}Recurrent neural networks}{24}{subsection.3.2.2}
\contentsline {subsection}{\numberline {3.2.3}Other types of networks}{24}{subsection.3.2.3}
\contentsline {section}{\numberline {3.3}Multilayer perceptron}{25}{section.3.3}
\contentsline {subsection}{\numberline {3.3.1}Why multilayer perceptrons?}{25}{subsection.3.3.1}
\contentsline {subsection}{\numberline {3.3.2}Mathematical model}{26}{subsection.3.3.2}
\contentsline {subsubsection}{Activation function of output neuron}{28}{section*.14}
\contentsline {subsubsection}{Matrix representation}{28}{section*.15}
\contentsline {section}{\numberline {3.4}Activation functions}{30}{section.3.4}
\contentsline {section}{\numberline {3.5}Training}{32}{section.3.5}
\contentsline {subsection}{\numberline {3.5.1}Cost functions}{33}{subsection.3.5.1}
\contentsline {section}{\numberline {3.6}Optimization}{34}{section.3.6}
\contentsline {subsection}{\numberline {3.6.1}Gradient descent variants}{34}{subsection.3.6.1}
\contentsline {subsection}{\numberline {3.6.2}Optimization algorithms}{35}{subsection.3.6.2}
\contentsline {subsubsection}{Momentum}{35}{section*.18}
\contentsline {subsubsection}{Adagrad}{36}{section*.19}
\contentsline {subsubsection}{Adadelta}{36}{section*.20}
\contentsline {subsubsection}{Adam}{37}{section*.21}
\contentsline {subsubsection}{Which optimizer to use?}{38}{section*.22}
\contentsline {subsection}{\numberline {3.6.3}Backpropagation}{38}{subsection.3.6.3}
\contentsline {subsubsection}{1. Forward propagation}{39}{section*.23}
\contentsline {subsubsection}{2. Backward propagation}{39}{section*.24}
\contentsline {subsubsection}{Matrix notation}{42}{section*.26}
\contentsline {subsubsection}{Training algorithm}{42}{section*.27}
\contentsline {chapter}{\numberline {4}Neural networks in molecular dynamics}{45}{chapter.4}
\contentsline {section}{\numberline {4.1}Neural network potentials}{45}{section.4.1}
\contentsline {subsection}{\numberline {4.1.1}Potentials using single neural network}{45}{subsection.4.1.1}
\contentsline {subsection}{\numberline {4.1.2}Potentials using multiple neural networks}{46}{subsection.4.1.2}
\contentsline {section}{\numberline {4.2}The Behler-Parinello method}{46}{section.4.2}
\contentsline {subsection}{\numberline {4.2.1}Symmetry functions}{47}{subsection.4.2.1}
\contentsline {subsubsection}{Radial symmetry functions}{48}{section*.29}
\contentsline {subsubsection}{Angular symmetry functions}{51}{section*.31}
\contentsline {subsubsection}{Setting the symmetry parameters}{51}{section*.33}
\contentsline {subsection}{\numberline {4.2.2}Symmetry functions and forces}{52}{subsection.4.2.2}
\contentsline {subsubsection}{Change of coordinates}{54}{section*.34}
\contentsline {subsection}{\numberline {4.2.3}Summary}{56}{subsection.4.2.3}
\contentsline {part}{II\hspace {1em}Implementation and results}{59}{part.2}
\contentsline {chapter}{\numberline {5}LAMMPS}{61}{chapter.5}
\contentsline {section}{\numberline {5.1}Installing LAMMPS}{61}{section.5.1}
\contentsline {section}{\numberline {5.2}LAMMPS input script}{62}{section.5.2}
\contentsline {section}{\numberline {5.3}LAMMPS structure}{66}{section.5.3}
\contentsline {section}{\numberline {5.4}Extending LAMMPS}{66}{section.5.4}
\contentsline {chapter}{\numberline {6}TensorFlow}{75}{chapter.6}
\contentsline {section}{\numberline {6.1}Installing TensorFlow}{76}{section.6.1}
\contentsline {section}{\numberline {6.2}TensorFlow basic usage}{77}{section.6.2}
\contentsline {subsection}{\numberline {6.2.1}Hello world}{77}{subsection.6.2.1}
\contentsline {subsection}{\numberline {6.2.2}Creating a neural network}{78}{subsection.6.2.2}
\contentsline {subsection}{\numberline {6.2.3}Visualizing the graph}{79}{subsection.6.2.3}
\contentsline {subsection}{\numberline {6.2.4}Training a NN with TensorFlow}{81}{subsection.6.2.4}
\contentsline {chapter}{\numberline {7}Constructing a neural network potential}{85}{chapter.7}
\contentsline {section}{\numberline {7.1}Selecting the reference set}{85}{section.7.1}
\contentsline {subsection}{\numberline {7.1.1}Iterative molecular dynamics sampling}{86}{subsection.7.1.1}
\contentsline {subsection}{\numberline {7.1.2}Sampling algorithms}{87}{subsection.7.1.2}
\contentsline {subsubsection}{Initial sampling}{88}{section*.40}
\contentsline {subsubsection}{Iterative sampling}{92}{section*.42}
\contentsline {subsubsection}{Summary}{93}{section*.43}
\contentsline {section}{\numberline {7.2}Constructing the symmetry function sets}{94}{section.7.2}
\contentsline {subsection}{\numberline {7.2.1}Initial set}{94}{subsection.7.2.1}
\contentsline {subsubsection}{Angular symmetry functions}{95}{section*.45}
\contentsline {subsubsection}{Number of symmetry functions}{95}{section*.47}
\contentsline {subsection}{\numberline {7.2.2}Adjusting the set}{97}{subsection.7.2.2}
\contentsline {subsubsection}{For each symmetry function, the range of function values should be as large as possible}{97}{section*.48}
\contentsline {subsubsection}{The set of values of two different symmetry functions on a given data set should not be strongly correlated}{97}{section*.49}
\contentsline {section}{\numberline {7.3}Setting hyperparameters}{98}{section.7.3}
\contentsline {subsection}{\numberline {7.3.1}Preconditioning the input data}{98}{subsection.7.3.1}
\contentsline {subsubsection}{Convergence speed vs evaluation speed}{99}{section*.50}
\contentsline {subsection}{\numberline {7.3.2}Activation functions and weight initialization}{100}{subsection.7.3.2}
\contentsline {subsection}{\numberline {7.3.3}Network architecture and overfitting}{101}{subsection.7.3.3}
\contentsline {subsubsection}{Other regularization teqhniques}{104}{section*.52}
\contentsline {subsection}{\numberline {7.3.4}Optimizer parameters}{104}{subsection.7.3.4}
\contentsline {subsection}{\numberline {7.3.5}Cost function}{105}{subsection.7.3.5}
\contentsline {subsection}{\numberline {7.3.6}Hyperparameter space exploration}{106}{subsection.7.3.6}
\contentsline {subsubsection}{Coordinate descent}{106}{section*.53}
\contentsline {subsubsection}{Grid search}{106}{section*.54}
\contentsline {subsubsection}{Random search}{107}{section*.55}
\contentsline {subsection}{\numberline {7.3.7}Summary}{107}{subsection.7.3.7}
\contentsline {section}{\numberline {7.4}Applying the neural network potential}{107}{section.7.4}
\contentsline {subsection}{\numberline {7.4.1}Transfer neural network from Python to C++}{107}{subsection.7.4.1}
\contentsline {chapter}{\numberline {8}Lennard-Jones validation}{111}{chapter.8}
\contentsline {section}{\numberline {8.1}Error in configuration space}{113}{section.8.1}
\contentsline {section}{\numberline {8.2}Many-neighbour Lennard-Jones}{114}{section.8.2}
\contentsline {subsection}{\numberline {8.2.1}Alternative way to obtain forces}{115}{subsection.8.2.1}
\contentsline {chapter}{\numberline {9}Neural network potential for Si}{119}{chapter.9}
\contentsline {part}{III\hspace {1em}Conclusions and future work}{121}{part.3}
\contentsline {chapter}{\numberline {10}The quality of the NNP}{123}{chapter.10}
\contentsline {chapter}{Appendices}{125}{section*.62}
\contentsline {chapter}{\numberline {A}Symmetry functions derivatives}{127}{Appendix.1.A}
